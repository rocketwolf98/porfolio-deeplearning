{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC3kPFJp3kye"
      },
      "source": [
        "# Creating a Linear Regression Model using PyTorch<br>\n",
        "By Kenneth Lim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhj8F-UR3v46"
      },
      "source": [
        "Featuring: California House Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQnMpff239z-"
      },
      "source": [
        "**About The Dataset**\n",
        "\n",
        "The US Census Bureau has published California Census Data which has 10 types of metrics such as the population, median income, median housing price, and so on for each block group in California. The dataset also serves as an input for project scoping and tries to specify the functional and nonfunctional r requirements for it.\n",
        "\n",
        "Problem Objective:\n",
        "The project aims at building a model of housing prices to predict median house values in California using the provided dataset. This model should learn from the data and be able to predict the median housing price in any district, given all the other metrics.\n",
        "\n",
        "Districts or block groups are the smallest geographical units for which the US Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people). There are 20,640 districts in the project dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlg6ZxsF4D51"
      },
      "source": [
        "| Feature              | Type                   | Description                                                                                     |\n",
        "|-----------------------|------------------------|-------------------------------------------------------------------------------------------------|\n",
        "| longitude             | numeric (float)        | Longitude value for the block in California, USA                                               |\n",
        "| latitude              | numeric (float)        | Latitude value for the block in California, USA                                                |\n",
        "| housing_median_age    | numeric (int)          | Median age of the house in the block                                                           |\n",
        "| total_rooms           | numeric (int)          | Count of the total number of rooms (excluding bedrooms) in all houses in the block             |\n",
        "| total_bedrooms        | numeric (float)        | Count of the total number of bedrooms in all houses in the block                               |\n",
        "| population            | numeric (int)          | Count of the total number of population in the block                                           |\n",
        "| households            | numeric (int)          | Count of the total number of households in the block                                           |\n",
        "| median_income         | numeric (float)        | Median of the total household income of all the houses in the block                            |\n",
        "| ocean_proximity       | categorical (string)   | Type of the landscape of the block <br> **Unique Values:** 'NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND' |\n",
        "| median_house_value    | numeric (int)          | Median of the household prices of all the houses in the block                                  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ermtHmAv4ZkQ"
      },
      "source": [
        "**What are we doing for now?**\n",
        "\n",
        "In this case just for experimentation, we will guess the location of the house based on the number of population, households, income, and the value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiSVbq0L4pqU"
      },
      "outputs": [],
      "source": [
        "#Importing essential packages\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDT7Vot74z-9",
        "outputId": "d030731f-f4ec-46c5-9b93-4e726d61ab76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'house-price' dataset.\n",
            "Path to dataset files: /kaggle/input/house-price\n"
          ]
        }
      ],
      "source": [
        "#Downloading dataset\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shibumohapatra/house-price\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Ro07aV4_H_"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/kaggle/input/house-price/1553768847-housing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9d1BLlm5IhO",
        "outputId": "e1af0f07-1184-455e-cb21-b3f2d0120d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   housing_median_age  20640 non-null  int64  \n",
            " 3   total_rooms         20640 non-null  int64  \n",
            " 4   total_bedrooms      20433 non-null  float64\n",
            " 5   population          20640 non-null  int64  \n",
            " 6   households          20640 non-null  int64  \n",
            " 7   median_income       20640 non-null  float64\n",
            " 8   ocean_proximity     20640 non-null  object \n",
            " 9   median_house_value  20640 non-null  int64  \n",
            "dtypes: float64(4), int64(5), object(1)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVqYRRZN5N6k"
      },
      "source": [
        "The only thing we will mind are the longitude, latitude, median income, house value, population and households so we will drop some of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1JhVQhM5ehU"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = ['housing_median_age', 'total_rooms', 'total_bedrooms', 'ocean_proximity']\n",
        "data.drop(cols_to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8piKup445kuk",
        "outputId": "5681f5fb-4632-49b4-97aa-3d1455c1cae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   population          20640 non-null  int64  \n",
            " 3   households          20640 non-null  int64  \n",
            " 4   median_income       20640 non-null  float64\n",
            " 5   median_house_value  20640 non-null  int64  \n",
            "dtypes: float64(3), int64(3)\n",
            "memory usage: 967.6 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTFr8eAY5oLO"
      },
      "source": [
        "*Now we will proceed with the workflow*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4aa5Oa2p5l07",
        "outputId": "8a7446bd-da84-4844-9154-3819337fb750"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0+cu126'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmkN9R2D5vU8",
        "outputId": "60dbb334-75f4-4249-fdb1-43cd2febaa52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda:0\n"
          ]
        }
      ],
      "source": [
        "#We can check whether we have gpu\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70rCQ6WL5w5U"
      },
      "outputs": [],
      "source": [
        "#Specifying inputs and arrays\n",
        "x_train = data.drop(['longitude', 'latitude'], axis=1)\n",
        "y_train = data[['longitude', 'latitude']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwR9U8zZ6WH9",
        "outputId": "18cdbbaa-cb10-4e72-e1bb-aa1e442cf5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20640, 4])\n",
            "torch.Size([20640, 2])\n"
          ]
        }
      ],
      "source": [
        "inputs = torch.from_numpy(x_train.values).float()\n",
        "targets = torch.from_numpy(y_train.values).float()\n",
        "print(inputs.size())\n",
        "print(targets.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgy5W-d6l1m"
      },
      "source": [
        "*We will be now utilizing the datat primitives of PyTorch, Dataset and Dataloader*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJGiv2Jl6XWQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnIX3FE46wZn",
        "outputId": "2a9db94b-a2c0-4ff0-c856-79d232700a55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[3.2200e+02, 1.2600e+02, 8.3252e+00, 4.5260e+05],\n",
              "         [2.4010e+03, 1.1380e+03, 8.3014e+00, 3.5850e+05],\n",
              "         [4.9600e+02, 1.7700e+02, 7.2574e+00, 3.5210e+05]]),\n",
              " tensor([[-122.2300,   37.8800],\n",
              "         [-122.2200,   37.8600],\n",
              "         [-122.2400,   37.8500]]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqVkEUOM6xsk"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_xyV-1A65tW"
      },
      "source": [
        "*DataLoader splits the dataset into batches. Quite handy expecially dealing with extremely larger datasets*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnRc2EXO6179"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7uTENXn7Fik",
        "outputId": "58b32e21-50c7-4f9e-9729-7a9a4cfcc252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.1230e+03, 3.4700e+02, 5.5792e+00, 2.1840e+05],\n",
            "        [7.1110e+03, 2.4190e+03, 3.3627e+00, 1.9790e+05],\n",
            "        [1.9390e+03, 4.8400e+02, 4.2875e+00, 1.7660e+05],\n",
            "        [7.4400e+02, 3.1200e+02, 2.6518e+00, 1.5610e+05],\n",
            "        [3.7400e+02, 1.8000e+02, 6.2673e+00, 3.5720e+05],\n",
            "        [1.7600e+03, 5.4200e+02, 4.0227e+00, 1.2650e+05],\n",
            "        [2.2320e+03, 8.2500e+02, 6.6659e+00, 5.0000e+05],\n",
            "        [2.2690e+03, 1.2320e+03, 5.7097e+00, 3.1670e+05]])\n",
            "tensor([[-118.4700,   34.2600],\n",
            "        [-117.9000,   33.7800],\n",
            "        [-118.3700,   34.2100],\n",
            "        [-122.3000,   38.2900],\n",
            "        [-118.3900,   33.9700],\n",
            "        [-119.5800,   36.7700],\n",
            "        [-121.8300,   37.2300],\n",
            "        [-118.4400,   34.0500]])\n"
          ]
        }
      ],
      "source": [
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7rDIuiR7Rp9"
      },
      "source": [
        "*We will now define the model using nn.Linear class from pytorch*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm77OOTV7JoC",
        "outputId": "86faceeb-0269-40a3-d72d-4c575fe9f96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=3, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Fully connected x2\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 3),   # first FC: input 4 → hidden 3\n",
        "    nn.ReLU(),         # non-linearity\n",
        "    nn.Linear(3, 2)    # second FC: hidden 3 → output 2\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra-FYa369kfX"
      },
      "source": [
        "Given that our prerequisite requires a double FCN, we will introduce Sequential, where we introduce non-linearity and a hidden layer for our model to generalize better from unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY5qmK7i8zFY"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaMTFaDx7chL",
        "outputId": "3e5fb64f-81a3-4c0d-a5ba-a67614735192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.2293,  0.3390,  0.3096, -0.4098],\n",
              "         [-0.0441,  0.3973,  0.3422,  0.2145],\n",
              "         [ 0.1209, -0.1670,  0.4479,  0.1457]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3035, -0.1168,  0.3317], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.2023, -0.4467, -0.4492],\n",
              "         [-0.5334,  0.2858,  0.3055]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.2968, -0.5370], requires_grad=True)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.parameters())  #model.param returns a generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBo7E4Ap7fmB",
        "outputId": "03c37d80-ca74-4311-a3bf-a38f9f5e9ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "#we can print the complexity by the number of parameters\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzYZZzIl7hnQ",
        "outputId": "4d661298-cbfc-46fc-c45c-edf3a69e1c22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-73014.5781,  47905.5625],\n",
              "        [-58015.4414,  38062.9414],\n",
              "        [-56818.6211,  37279.1055],\n",
              "        ...,\n",
              "        [-14964.6865,   9817.5088],\n",
              "        [-13721.3438,   9001.6895],\n",
              "        [-14520.3584,   9526.1387]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQlDiBUY7lk0"
      },
      "source": [
        "*We will now define the loss functon from the **nn** module*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZfkfgU_7jsQ"
      },
      "outputs": [],
      "source": [
        "criterion_mse = nn.MSELoss()\n",
        "criterion_softmax_cross_entropy_loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Al5P_n17tyB",
        "outputId": "ba0f520e-55f3-447f-c279-48edf257ecca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0437e+09, grad_fn=<MseLossBackward0>)\n",
            "1043722560.0\n"
          ]
        }
      ],
      "source": [
        "mse = criterion_mse(preds, targets)\n",
        "print(mse)\n",
        "print(mse.item())  ##print out the loss number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8muN_ii-7z25"
      },
      "source": [
        "*Next is the optimizer*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB2Ph_2x7wvF"
      },
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "#momentum update the weight based on past gradients also, which will be useful for getting out of local max/min\n",
        "#If our momentum parameter was $0.9$, we would get our current grad + the multiplication of the gradient\n",
        "#from one time step ago by $0.9$, the one from two time steps ago by $0.9^2 = 0.81$, etc.\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSJwXy1198Sd"
      },
      "source": [
        "*Then we start training*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzjBmInF719X"
      },
      "outputs": [],
      "source": [
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "\n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "\n",
        "            xb.to(device) #move them to gpu if possible, if not, it will be cpu\n",
        "            yb.to(device)\n",
        "\n",
        "            # 1. Predict\n",
        "            pred = model(xb)\n",
        "\n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # 3. Calculate gradient\n",
        "            opt.zero_grad()  #if not, the gradients will accumulate\n",
        "            loss.backward()\n",
        "\n",
        "            # Print out the gradients.\n",
        "            # print ('dL/dw: ', model.weight.grad)\n",
        "            # print ('dL/db: ', model.bias.grad)\n",
        "\n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "\n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            sys.stdout.write(\"\\rEpoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zcMEkGR-KXo",
        "outputId": "60364ca1-8af2-471c-85e8-e723321e7107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1000/1000], Loss: 5.0568"
          ]
        }
      ],
      "source": [
        "#train for 1000 epochs\n",
        "fit(1000, model, criterion_mse, opt, train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5s_HI9z-OWK",
        "outputId": "4492f048-6e74-401a-e25e-516d75603c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.28816032409668\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "loss = criterion_mse(preds, targets)\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBmRJW76GVgi"
      },
      "source": [
        "We may conclude with the fact that the maximum likelihood for error is around 4.29, which is somewhat closer to actual values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUgbZ9gVGdtT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
